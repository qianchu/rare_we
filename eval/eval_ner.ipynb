{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "from chainer import cuda\n",
    "from context2vec.common.context_models import Toks\n",
    "from context2vec.common.model_reader import ModelReader\n",
    "import gensim\n",
    "import unittest\n",
    "#define models\n",
    "CONTEXT2VEC='context2vec'\n",
    "CONTEXT2VEC_SUB='context2vec-skipgram'\n",
    "A_LA_CARTE='alacarte'\n",
    "SKIPGRAM='skipgram'\n",
    "SKIPGRAM_ISF='skipgram_isf'\n",
    "CONTEXT2VEC_SUB__SKIPGRAM_ISF='context2vec-skipgram?skipgram'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "def remove_stopword(word):\n",
    "    stopw=stopwords.words('english')\n",
    "    stopw=[word.encode('utf-8') for word in stopw]\n",
    "    if word not in stopw:\n",
    "        return word\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#general related functions\n",
    "def read_skipgram(model_param_file):\n",
    "        if not model_param_file.endswith('txt'):\n",
    "            model_skipgram = gensim.models.Word2Vec.load(model_param_file)\n",
    "        else:\n",
    "            model_skipgram = KeyedVectors.load_word2vec_format(model_param_file)\n",
    "       \n",
    "        return model_skipgram\n",
    "\n",
    "def read_context2vec(model_param_file,gpu):\n",
    "    model_reader = ModelReader(model_param_file,gpu)\n",
    "    w = xp.array(model_reader.w)\n",
    "    index2word = model_reader.index2word\n",
    "    word2index=model_reader.word2index\n",
    "    model = model_reader.model\n",
    "    return w,index2word,word2index,model\n",
    "\n",
    "def process_sent(test_s,test_w):\n",
    "    test_s=test_s.replace(test_w, ' '+test_w+' ')\n",
    "    words=test_s.split()\n",
    "    pos=words.index(test_w)\n",
    "    return words,pos\n",
    "\n",
    "def load_w2salience(model_w2v,w2salience_f):\n",
    "    w2salience={}\n",
    "    with open(w2salience_f) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            if line=='':\n",
    "                continue\n",
    "            if line.startswith('sentence total'):\n",
    "                sent_total=int(line.split(':')[1])\n",
    "                continue\n",
    "            w,w_count,s_count=line.split('\\t')\n",
    "            if model_w2v.wv.__contains__(w):\n",
    "                    w2salience[w]=math.log(1+sent_total/float(s_count))\n",
    "    return w2salience\n",
    "\n",
    "def produce_top_n_simwords(w_filter,context_embed,n_result,index2word,debug=False):\n",
    "        #assume that w_filter is already normalized\n",
    "        context_embed = context_embed / sqrt((context_embed * context_embed).sum())\n",
    "        similarity_scores=[]\n",
    "#         print('producing top {0} simwords'.format(n_result))\n",
    "        similarity = (w_filter.dot(context_embed)+1.0)/2\n",
    "        top_words_i=[]\n",
    "        top_words=[]\n",
    "        count = 0\n",
    "        for i in (-similarity).argsort():                \n",
    "                    if xp.isnan(similarity[i]):\n",
    "                        continue\n",
    "                    if debug==True:\n",
    "                        try:\n",
    "                            print('{0}: {1}'.format(str(index2word[int(i)]), str(similarity[int(i)])))\n",
    "                        except UnicodeEncodeError as e:\n",
    "                            print (e)\n",
    "                            \n",
    "                    count += 1\n",
    "                    top_words_i.append(int(i))\n",
    "                    top_words.append(index2word[int(i)])\n",
    "                    similarity_scores.append(float(similarity[int(i)]))\n",
    "                    if count == n_result:\n",
    "                        break\n",
    "\n",
    "        top_vec=w_filter[top_words_i,:]\n",
    "        return top_vec,xp.array(similarity_scores),top_words\n",
    " \n",
    "\n",
    "def lg_model_out_w2v(top_words,w_target,word2index_target):\n",
    "        # lg model substitutes in skipgram embedding\n",
    "        top_vec=[]\n",
    "        index_list=[]\n",
    "        for i,word in enumerate(top_words):\n",
    "            try :\n",
    "                top_vec.append(w_target[word2index_target[word]])\n",
    "                index_list.append(i)\n",
    "            except KeyError as e:\n",
    "                pass\n",
    "#                 print ('lg subs {0} not in w2v'.format(e))\n",
    "        if top_vec==[]:\n",
    "            print ('no lg subs in w2v space')\n",
    "            return xp.array([]),[]\n",
    "        else:\n",
    "            return xp.stack(top_vec),index_list\n",
    "    \n",
    "def load_transform(Afile,model):\n",
    "    '''loads the transform from a text file\n",
    "    Args:\n",
    "    Afile: string; transform file name\n",
    "    Returns:\n",
    "    numpy array\n",
    "    '''\n",
    "    if Afile==None:\n",
    "        return None\n",
    "    elif Afile.endswith('bin'):\n",
    "        M = np.fromfile(Afile, dtype=FLOAT)\n",
    "        d = int(np.sqrt(M.shape[0]))\n",
    "        print (d)\n",
    "        assert d == next(iter(model.values())).shape[0], \"induction matrix dimension and word embedding dimension must be the same\"\n",
    "        M = M.reshape(d, d)\n",
    "        M=xp.array(M)\n",
    "        return M\n",
    "    elif Afile.endswith('txt'):\n",
    "        with open(Afile, 'r') as f:\n",
    "            return xp.array(np.vstack([np.array([FLOAT(x) for x in line.split()]) for line in f]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main class\n",
    "\n",
    "class ContextModel():\n",
    "    def __init__(self, context2vec_param_file,skipgram_param_file, model_type, gpu, n_result, ws_f,matrix_f):\n",
    "        self.gpu=gpu\n",
    "        self.model_type=model_type\n",
    "        self.n_result=20 if n_result ==None else n_result\n",
    "        \n",
    "        self.load_model(context2vec_param_file,skipgram_param_file)\n",
    "        self.word_weight=load_w2salience(self.model_skipgram,ws_f) if ws_f!=None else None\n",
    "        self.alacarte_m=load_transform(matrix_f,{word:self.model_skipgram.wv.__getitem__(word) for word in self.model_skipgram.wv.vocab})\n",
    "\n",
    "   \n",
    "    def load_model(self, context2vec_param_file,skipgram_param_file):\n",
    "        if context2vec_param_file!=None:\n",
    "            self.context2vec_w,self.context2vec_index2word,self.context2vec_word2index,self.context2vec_model=read_context2vec(context2vec_param_file,self.gpu)\n",
    "        elif skipgram_param_file !=None:\n",
    "            self.model_skipgram=read_skipgram(skipgram_param_file)\n",
    "     \n",
    "    def compute_context_rep(self,test_s,test_w,model):\n",
    "        words,pos=process_sent(test_s,test_w)        \n",
    "        if model==CONTEXT2VEC:\n",
    "            context_rep=self.context2vec_model(words, pos)\n",
    "        elif model==CONTEXT2VEC_SUB:\n",
    "            context_rep=self.context2vec_sub(word,pos)\n",
    "        elif model==SKIPGRAM or model==SKIPGRAM_ISF:\n",
    "            context_rep=self.skipgram_context(words, pos)\n",
    "        elif model==A_LA_CARTE:\n",
    "            context_rep=self.skipgram_context(words, pos)\n",
    "        else:\n",
    "            print ('WARNING: incorrect model type{0}'.format(model))\n",
    "        return context_rep\n",
    "    \n",
    "    def compute_context_reps(self,test_ss,test_w,model):  \n",
    "        print ('model type is :{0}'.format(model_type))\n",
    "        context_out=[]\n",
    "        for test_id in range(len(test_ss)):\n",
    "            test_s=test_ss[test_id]\n",
    "            test_s=test_s.lower().strip()\n",
    "            context_out.append(self.compute_context_rep(test_s,test_w,model))\n",
    "        \n",
    "        return contexts_out\n",
    "    \n",
    "    def compute_context_reps_ensemble(self,test_ss,test_w):\n",
    "        context_out_ensemble=[]\n",
    "        for model in self.model_type:\n",
    "            contexts_out=self.compute_context_reps(test_ss,test_w,model)\n",
    "            contxt_out=self.compute_context_reps_aggregate(contexts_out)\n",
    "            context_out_ensemble.append(context_out)\n",
    "        context_out=sum(context_out_ensemble)/len(context_out_ensemble)\n",
    "        return context_out\n",
    "    \n",
    "    def compute_context_reps_aggregate(self,contexts_out,model):\n",
    "        if model==SKIPGRAM or SKIPGRAM_ISF or A_LA_CARTE:\n",
    "            context_out,context_weights=zip(* contexts_out)\n",
    "            context_out=sum(context_out)/sum(context_weights)\n",
    "        else:\n",
    "            context_out=sum(contexts_out)/len(contexts_out)\n",
    "\n",
    "        if model==A_LA_CARTE:\n",
    "            context_out=self.alacarte_m.dot(contexts_out)\n",
    "        return context_out\n",
    "    \n",
    "    \n",
    "    def skipgram_context(self,words,pos):\n",
    "        context_wvs=[]\n",
    "        weights=[]\n",
    "        for i,word in enumerate(words):\n",
    "            if i != pos: #surroudn context words\n",
    "                if word in self.model_skipgram and remove_stopword(word)!=None:\n",
    "                    if self.word_weight!=None:\n",
    "                        weights.append(self.word_weight[word])\n",
    "                        context_wvs.append(model[word])                   \n",
    "                    else:\n",
    "                        #equal weights per word\n",
    "                        context_wvs.append(model[word])\n",
    "                        weights.append(1.0)\n",
    "                else:\n",
    "                    pass\n",
    "        context_embed=sum(np.array(context_wvs)*np.array(weights).reshape(len(weights),1))#/sum(weights)\n",
    "    #     print ('skipgram context sum:', context_embed[:10])\n",
    "        return (sum(weights),context_embed)\n",
    "\n",
    "  \n",
    "    \n",
    "    def context2vec_sub(self,word,pos):\n",
    "        \n",
    "        context_rep=self.context2vec_model(words, pos)\n",
    "        top_vec,sim_scores,top_words=produce_top_n_simwords(self.context2vec_w,context_rep, self.n_result, self.context2vec_index2word, debug=True)\n",
    "        top_vec,index_list=lg_model_out_w2v(top_words,self.model_skipgram.wv.vectors,self.model_skipgram.wv.index2word) \n",
    "        \n",
    "        sim_scores=sim_scores[index_list] #weighted by substitute probability\n",
    "        context_rep=xp.array(sum(top_vec*((sim_scores/sum(sim_scores)).reshape(len(sim_scores),1))))\n",
    "        return context_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in parameters and setup\n",
    "class ArgTest:\n",
    "    def __init__(self,model_type,gpu,context2vec_param_file=None, skipgram_param_file=None, n_result=None,w2salience_f=None,matrix_f=None):\n",
    "        self.context2vec_param_file=context2vec_param_file\n",
    "        self.skipgram_param_file=skipgram_param_file\n",
    "        self.model_type=model_type\n",
    "        self.n_result=n_result\n",
    "        self.gpu=gpu\n",
    "        self.w2salience_f=w2salience_f\n",
    "        self.matrix_f=matrix_f\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Evaluate on long tail emerging ner')\n",
    "    parser.add_argument('--cm',  type=str,\n",
    "                        help='context2vec_param_file',dest='context2vec_param_file',default=None)\n",
    "    parser.add_argument('--sm',type=str, default=None, help='skipgram_param_file')\n",
    "    parser.add_argument('--m', dest='model_type', type=str,\n",
    "                        help='<model_type: context2vec; context2vec-skipgram (context2vec substitutes in skipgram space); context2vec-skipgram?skipgram (context2vec substitutes in skipgram space plus skipgram context words)>')\n",
    "    parser.add_argument('--d', dest='data', type=str, help='data file')\n",
    "    parser.add_argument('--g', dest='gpu',type=int, default=-1,help='gpu, default is -1')\n",
    "    parser.add_argument('--ws', dest='w2salience_f',type=str, default=None,help='word2salience file, optional')\n",
    "    parser.add_argument('--n_result',default=20,dest='n_result',type=int,help='top n result for language model substitutes')\n",
    "    parser.add_argument('--ma', dest='matrix_f',type=str,default=None,help='matrix file for a la carte')\n",
    "    args = parser.parse_args()\n",
    "    return args  \n",
    "    \n",
    "        \n",
    "def read_args():\n",
    "    if sys.argv[0]=='/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py':\n",
    "        args=ArgTest(\n",
    "#             context2vec_param_file='../models/context2vec/model_dir/MODEL-wiki.params.12',\n",
    "            skipgram_param_file='../models/wiki_all.model/wiki_all.sent.split.model',\n",
    "            model_type=SKIPGRAM,\n",
    "            n_result=20,\n",
    "            gpu=-1,\n",
    "#             w2salience_f='../corpora/corpora/wiki.all.utf8.sent.split.tokenized.vocab',\n",
    "#             matrix_f='../models/ALaCarte/transform/nonce_samecorpus.bin'\n",
    "\n",
    "        )\n",
    "    else:\n",
    "        args=parse_args()\n",
    "    return args\n",
    "\n",
    " \n",
    "def gpu_config(gpu):\n",
    "    if gpu >= 0:\n",
    "        cuda.check_cuda_available()\n",
    "        cuda.get_device(gpu).use()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "\n",
    "class TestCases(unittest.TestCase):\n",
    "        \n",
    "    def test_skipgram(self):\n",
    "        super(TestCases, self).init()\n",
    "        self.\n",
    "#         CM=ContextModel(skipgram_param_file='../models/wiki_all.model/wiki_all.sent.split.model',gpu=1,model_type=SKIPGRAM)\n",
    "        pass\n",
    "     \n",
    "class Test(list):\n",
    "    \n",
    "    def test(self):\n",
    "        super\n",
    "    \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "#     args=read_args()\n",
    "    \n",
    "#     #gpu setup\n",
    "#     gpu_config(args.gpu)\n",
    "#     xp = cuda.cupy if args.gpu >= 0 else np\n",
    "    \n",
    "#     #read in model\n",
    "#     CM=ContextModel(args.context2vec_param_file, args.skipgram_param_file, args.model_type, args.n_result, args.gpu,args.w2salience_f,args.matrix_f)\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
